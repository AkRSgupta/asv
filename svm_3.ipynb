{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3AVHNLu88m0A"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import loguniform\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 1. Data Loading & Preprocessing\n",
        "# ========================\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\"\n",
        "columns = ['letter', 'x-box', 'y-box', 'width', 'height', 'onpix', 'x-bar',\n",
        "           'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege',\n",
        "           'xegvy', 'y-ege', 'yegvx']\n",
        "data = pd.read_csv(url, header=None, names=columns)\n",
        "\n",
        "# Convert letters to numerical labels\n",
        "le = LabelEncoder()\n",
        "data['label'] = le.fit_transform(data['letter'])\n",
        "\n",
        "# Split features and target\n",
        "X = data.drop(['letter', 'label'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "qUDNBA5J8tAA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 2. Create 10 Data Splits\n",
        "# ========================\n",
        "\n",
        "splits = []\n",
        "for i in range(10):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y, test_size=0.3, random_state=i\n",
        "    )\n",
        "    splits.append((X_train, X_test, y_train, y_test))"
      ],
      "metadata": {
        "id": "gzvPvFe08veJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 3. SVM Optimization\n",
        "# ========================\n",
        "\n",
        "# Define parameter space\n",
        "param_dist = {\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'C': loguniform(1e0, 1e2),\n",
        "    'gamma': loguniform(1e-4, 1e-1)\n",
        "}\n",
        "\n",
        "results = []\n",
        "best_sample_data = None\n",
        "max_accuracy = 0\n",
        "\n",
        "for sample_num in range(10):\n",
        "    print(f\"\\nProcessing Sample #{sample_num+1}\")\n",
        "    X_train, X_test, y_train, y_test = splits[sample_num]\n",
        "\n",
        "    # Run randomized search\n",
        "    search = RandomizedSearchCV(\n",
        "        SVC(),\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=100,\n",
        "        cv=5,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    search.fit(X_train, y_train)\n",
        "\n",
        "    # Store results\n",
        "    best_acc = search.best_score_ * 100\n",
        "    best_params = search.best_params_\n",
        "\n",
        "    results.append({\n",
        "        'Sample #': f\"S{sample_num+1}\",\n",
        "        'Best Accuracy': f\"{best_acc:.2f}%\",\n",
        "        'Kernel': best_params['kernel'],\n",
        "        'Nu': f\"{best_params['C']:.3f}\",\n",
        "        'Epsilon': f\"{best_params['gamma']:.5f}\"\n",
        "    })\n",
        "\n",
        "    # Track best sample for convergence plot\n",
        "    if best_acc > max_accuracy:\n",
        "        max_accuracy = best_acc\n",
        "        best_sample_data = {\n",
        "            'cv_results': search.cv_results_,\n",
        "            'sample_num': sample_num+1\n",
        "        }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDM7Tx7G848_",
        "outputId": "670a4a3b-ec0d-4870-ee5c-061674f4d547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Sample #1\n",
            "\n",
            "Processing Sample #2\n",
            "\n",
            "Processing Sample #3\n",
            "\n",
            "Processing Sample #4\n",
            "\n",
            "Processing Sample #5\n",
            "\n",
            "Processing Sample #6\n",
            "\n",
            "Processing Sample #7\n",
            "\n",
            "Processing Sample #8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 4. Generate Results Table\n",
        "# ========================\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Results Table:\")\n",
        "print(results_df[['Sample #', 'Best Accuracy', 'Kernel', 'Nu', 'Epsilon']])"
      ],
      "metadata": {
        "id": "3Kw9YMc09vfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 5. Convergence Graph\n",
        "# ========================\n",
        "\n",
        "if best_sample_data:\n",
        "    # Extract cumulative maximum accuracy\n",
        "    scores = best_sample_data['cv_results']['mean_test_score']\n",
        "    iterations = range(1, 101)\n",
        "    cum_max = np.maximum.accumulate(scores)\n",
        "\n",
        "    # Plot settings\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(iterations, cum_max, marker='o', linestyle='--')\n",
        "    plt.title(f\"Convergence Graph for Best Sample (S{best_sample_data['sample_num']})\")\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Best Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.savefig('convergence_graph.png')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "46VY3GoJ9y_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 6. Save Results\n",
        "# ========================\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv('svm_optimization_results.csv', index=False)\n",
        "\n",
        "# Save convergence graph\n",
        "plt.savefig('convergence_graph.png')\n",
        "\n",
        "print(\"\\nAll results saved successfully!\")"
      ],
      "metadata": {
        "id": "D3BSChob91Wo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}